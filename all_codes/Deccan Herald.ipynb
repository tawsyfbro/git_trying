{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da507ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages available for Bangladesh is 3\n",
      "Number of news links scraped: 20\n",
      "Link 1 added\n",
      "Link 2 added\n",
      "Link 3 added\n",
      "Link 4 added\n",
      "Link 5 added\n",
      "Link 6 added\n",
      "Link 7 added\n",
      "Link 8 added\n",
      "Link 9 added\n",
      "Link 10 added\n",
      "Link 11 added\n",
      "Link 12 added\n",
      "Link 13 added\n",
      "Link 14 added\n",
      "Link 15 added\n",
      "Link 16 added\n",
      "Link 17 added\n",
      "Link 18 added\n",
      "Link 19 added\n",
      "Link 20 added\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content_summary</th>\n",
       "      <th>title_translation</th>\n",
       "      <th>content_translation</th>\n",
       "      <th>summary translation</th>\n",
       "      <th>author</th>\n",
       "      <th>country</th>\n",
       "      <th>source_localtime</th>\n",
       "      <th>bangladesh_localtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.deccanherald.com//india/mizoram/mi...</td>\n",
       "      <td>Mizoram not to collect biometric data of Myanm...</td>\n",
       "      <td>Aizawl: Mizoram Chief Minister Lalduhoma on Th...</td>\n",
       "      <td>The Chief Minister said that the Centre is cur...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PTI</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-29 10:15:00</td>\n",
       "      <td>2024-02-29 10:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.deccanherald.com//india/india-bang...</td>\n",
       "      <td>India, Bangladesh DG-level border talks in Dha...</td>\n",
       "      <td>New Delhi: India and Bangladesh will hold thei...</td>\n",
       "      <td>A delegation led by Border Security Force (BSF...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PTI</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-29 06:48:00</td>\n",
       "      <td>2024-02-29 07:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.deccanherald.com//india/india-bang...</td>\n",
       "      <td>India, Bangladesh recognise their constitution...</td>\n",
       "      <td>Dhaka: Chief Justice of India D Y Chandrachud ...</td>\n",
       "      <td>The CJI spoke at the valedictory function of a...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PTI</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-24 16:16:00</td>\n",
       "      <td>2024-02-24 16:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.deccanherald.com//world/eight-rohi...</td>\n",
       "      <td>Eight Rohingya refugees injured in fire at cam...</td>\n",
       "      <td>Dhaka: Eight Rohingya refugees were injured on...</td>\n",
       "      <td>Bangladesh has relocated around 32,000 people ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-24 10:11:00</td>\n",
       "      <td>2024-02-24 10:41:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.deccanherald.com//india/biz-govt-l...</td>\n",
       "      <td>Government allows 54,760 tons of onion exports...</td>\n",
       "      <td>New Delhi: Amid export ban on onion, India on ...</td>\n",
       "      <td>Consumer Affairs Secretary Rohit Kumar Singh s...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PTI</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-22 16:01:00</td>\n",
       "      <td>2024-02-22 16:31:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.deccanherald.com//india/mizoram/mi...   \n",
       "1  https://www.deccanherald.com//india/india-bang...   \n",
       "2  https://www.deccanherald.com//india/india-bang...   \n",
       "3  https://www.deccanherald.com//world/eight-rohi...   \n",
       "4  https://www.deccanherald.com//india/biz-govt-l...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Mizoram not to collect biometric data of Myanm...   \n",
       "1  India, Bangladesh DG-level border talks in Dha...   \n",
       "2  India, Bangladesh recognise their constitution...   \n",
       "3  Eight Rohingya refugees injured in fire at cam...   \n",
       "4  Government allows 54,760 tons of onion exports...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Aizawl: Mizoram Chief Minister Lalduhoma on Th...   \n",
       "1  New Delhi: India and Bangladesh will hold thei...   \n",
       "2  Dhaka: Chief Justice of India D Y Chandrachud ...   \n",
       "3  Dhaka: Eight Rohingya refugees were injured on...   \n",
       "4  New Delhi: Amid export ban on onion, India on ...   \n",
       "\n",
       "                                     content_summary title_translation  \\\n",
       "0  The Chief Minister said that the Centre is cur...              None   \n",
       "1  A delegation led by Border Security Force (BSF...              None   \n",
       "2  The CJI spoke at the valedictory function of a...              None   \n",
       "3  Bangladesh has relocated around 32,000 people ...              None   \n",
       "4  Consumer Affairs Secretary Rohit Kumar Singh s...              None   \n",
       "\n",
       "  content_translation summary translation   author     country  \\\n",
       "0                None                None      PTI  bangladesh   \n",
       "1                None                None      PTI  bangladesh   \n",
       "2                None                None      PTI  bangladesh   \n",
       "3                None                None  Reuters  bangladesh   \n",
       "4                None                None      PTI  bangladesh   \n",
       "\n",
       "     source_localtime bangladesh_localtime  \n",
       "0 2024-02-29 10:15:00  2024-02-29 10:45:00  \n",
       "1 2024-02-29 06:48:00  2024-02-29 07:18:00  \n",
       "2 2024-02-24 16:16:00  2024-02-24 16:46:00  \n",
       "3 2024-02-24 10:11:00  2024-02-24 10:41:00  \n",
       "4 2024-02-22 16:01:00  2024-02-22 16:31:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "\n",
    "page =  1\n",
    "BASE_URL = \"https://www.deccanherald.com/\"\n",
    "country = \"bangladesh\"\n",
    "initial_url = f\"{BASE_URL}search/{page}?q={country}\"\n",
    "\n",
    "\n",
    "#NEED TO FIRST LOAD USING SELENIUM THEN YOU CAN USE driver.page_source FOR FURTHER SCRAPING \n",
    "\n",
    "#COUNTING NUMBER OF PAGES AVAILABLE FOR BANGLADESH\n",
    "\n",
    "#SINCE IT'S A HUGE NUMBER, USING FIRST 2-3 PAGES FOR EXAMPLE. WHILE LOOP WORKS TO FIND TOTAL PAGES. \n",
    "\n",
    "count = 0\n",
    "\n",
    "for page in range(1,4):\n",
    "    \n",
    "    initial_url = f\"{BASE_URL}search/{page}?q={country}\"\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(initial_url)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    #CONTENT DIV WILL BE AVAILABLE IF PAGE EXISTS.\n",
    "    \n",
    "    content_div_available = soup.find('div', class_ = 'listing-story-card hide-mobile Z6Zei')\n",
    "    \n",
    "    if not content_div_available:\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        page+=1\n",
    "        count+=1\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "        \n",
    "print(f'Number of pages available for Bangladesh is {count}')\n",
    "\n",
    "#SCRAPING ALL NEWS LINKS FOR FIRST TWO PAGES\n",
    "news_links = []\n",
    "\n",
    "for page in range(1,3):\n",
    "    \n",
    "    initial_url = f\"{BASE_URL}search/{page}?q={country}\"\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(initial_url)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    main_div = soup.find_all('div', class_ = 'listing-story-card hide-mobile Z6Zei')\n",
    "\n",
    "    for link_div in main_div:\n",
    "\n",
    "        link = link_div.find('a').get('href')\n",
    "        news_links.append(link)\n",
    "    \n",
    "    time.sleep(5)\n",
    "        \n",
    "    driver.quit()\n",
    "    \n",
    "print(f'Number of news links scraped: {len(news_links)}')\n",
    "\n",
    "\n",
    "#SCRAPING THE NEWS SITES\n",
    "\n",
    "data_list = []\n",
    "counter = 0\n",
    "\n",
    "for url in news_links:\n",
    "    \n",
    "        link = f'{BASE_URL}{url}'\n",
    "\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        country = 'bangladesh'\n",
    "\n",
    "        #TITLE \n",
    "        title_tag = soup.find('meta', {'name':'title'})\n",
    "        title  = title_tag.get('content') if title_tag else 'Title not found'\n",
    "        title_translation = 'None'\n",
    "\n",
    "        #AUTHOR\n",
    "\n",
    "        author_tag = soup.find('meta', {'name':'author'})\n",
    "        author  = author_tag.get('content') if author_tag else 'Author not found'\n",
    "        \n",
    "\n",
    "        #DATE\n",
    "\n",
    "        date_data = soup.find('div', class_ = 'ehN3D')\n",
    "\n",
    "        if date_data:\n",
    "\n",
    "            cleaned_date_data = date_data.text.split('Updated ')[1].split(' IST')[0]\n",
    "            source_localtime = datetime.strptime(cleaned_date_data, '%d %B %Y, %H:%M')\n",
    "            bangladesh_localtime = source_localtime + timedelta(minutes = 30)\n",
    "\n",
    "        else:\n",
    "\n",
    "            date_data = 'Date data not found'\n",
    "\n",
    "        #CONTENT SUMMMARY \n",
    "\n",
    "        content_summary_tag = soup.find('div', {'data-test-id':'subheadline'})\n",
    "        content_summary = content_summary_tag.text if content_summary_tag else 'Content Summary not found'\n",
    "        summary_translation = 'None'\n",
    "\n",
    "        \n",
    "\n",
    "        #CONTENT\n",
    "\n",
    "        content =[]\n",
    "\n",
    "        all_content_divs = soup.find_all('div', {'id':'text-element-with-ad'})\n",
    "\n",
    "        for each_content_div in all_content_divs:\n",
    "            content.append(each_content_div.text)\n",
    "\n",
    "        full_content = ''.join(content)\n",
    "        full_content = re.sub('\\xa0',' ',full_content)\n",
    "        full_content = re.sub('\\n|\\r',' ',full_content)\n",
    "        content_translation = 'None'\n",
    "        \n",
    "        \n",
    "        data_dict = {\n",
    "        \"url\": link,\n",
    "        \"title\": title,\n",
    "        \"content\": full_content,\n",
    "        \"content_summary\": content_summary,\n",
    "        \"title_translation\":title_translation,\n",
    "        \"content_translation\":content_translation,\n",
    "        \"summary translation\":summary_translation,\n",
    "        \"author\": author,\n",
    "        \"country\": country,\n",
    "        'source_localtime': source_localtime,\n",
    "        'bangladesh_localtime': bangladesh_localtime\n",
    "\n",
    "    }\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "        if (full_content != \"Content Not Found\" and content_summary != 'Content summary not found'):\n",
    "\n",
    "                if data_dict not in data_list:\n",
    "                        # Adding to data list\n",
    "                        data_list.append(data_dict)\n",
    "                        print(f'Link {counter} added')\n",
    "        else:\n",
    "                print(f'Link {counter}')\n",
    "                print('Skipped due to missing info.')\n",
    "                \n",
    "                \n",
    "df = pd.DataFrame(data_list)\n",
    "df.head()\n",
    "\n",
    "csv_filename = f\"{country}_Deccan_Herald.csv\"\n",
    "\n",
    "# Checking if the CSV file already exists\n",
    "if os.path.exists(csv_filename):\n",
    "    existing_df = pd.read_csv(csv_filename)\n",
    "    # Merging new and existing dataframe\n",
    "    df = pd.concat([existing_df, pd.DataFrame(data_list)], ignore_index=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"bangladesh_localtime\"])  # Converting the \"date\" column to datetime\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)  # Sorting the date\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)  \n",
    "else:\n",
    "    # If csv file does not exist, then we create a new CSV file with the scraped data\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
