{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66435fa6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link 1 added\n",
      "Link 2 added\n",
      "Link 3 added\n",
      "Link 4 added\n",
      "Link 5 added\n",
      "Link 6 added\n",
      "Link 7 added\n",
      "Link 8 added\n",
      "Link 9 added\n",
      "Link 10 added\n",
      "Link 11 added\n",
      "Link 12 added\n",
      "Link 13 added\n",
      "Link 14 added\n",
      "Link 15 added\n",
      "Link 16 added\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content_summary</th>\n",
       "      <th>title_translation</th>\n",
       "      <th>content_translation</th>\n",
       "      <th>summary translation</th>\n",
       "      <th>author</th>\n",
       "      <th>country</th>\n",
       "      <th>source_localtime</th>\n",
       "      <th>bangladesh_localtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.morungexpress.com/from-asia-to-afr...</td>\n",
       "      <td>From Asia to Africa, 'Vishwaguru' India plays ...</td>\n",
       "      <td>In yet another proof of its emergence as an em...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>IANS</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>2024-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.morungexpress.com/nagaland-coal-re...</td>\n",
       "      <td>Nagaland coal revenue plummets: Rs 6 crore sho...</td>\n",
       "      <td>Kohima | March 1The revenue generated from coa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Morung Express News</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>2024-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.morungexpress.com/nitin-gadkari-sa...</td>\n",
       "      <td>Nitin Gadkari sanctions Rs 3,371cr for 4-lanin...</td>\n",
       "      <td>Union Minister for Road Transport and Highways...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>IANS</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>2024-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.morungexpress.com/central-contract...</td>\n",
       "      <td>Central Contracts: Hardik Pandya’s case is dif...</td>\n",
       "      <td>Former Indian cricketer-turned-commentator Aak...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>IANS</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>2024-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.morungexpress.com/death-toll-in-ba...</td>\n",
       "      <td>Death toll in Bangladesh building fire rises t...</td>\n",
       "      <td>The death toll in the fire at a multi-storey b...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>IANS</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>2024-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.morungexpress.com/from-asia-to-afr...   \n",
       "1  https://www.morungexpress.com/nagaland-coal-re...   \n",
       "2  https://www.morungexpress.com/nitin-gadkari-sa...   \n",
       "3  https://www.morungexpress.com/central-contract...   \n",
       "4  https://www.morungexpress.com/death-toll-in-ba...   \n",
       "\n",
       "                                               title  \\\n",
       "0  From Asia to Africa, 'Vishwaguru' India plays ...   \n",
       "1  Nagaland coal revenue plummets: Rs 6 crore sho...   \n",
       "2  Nitin Gadkari sanctions Rs 3,371cr for 4-lanin...   \n",
       "3  Central Contracts: Hardik Pandya’s case is dif...   \n",
       "4  Death toll in Bangladesh building fire rises t...   \n",
       "\n",
       "                                             content content_summary  \\\n",
       "0  In yet another proof of its emergence as an em...            None   \n",
       "1  Kohima | March 1The revenue generated from coa...            None   \n",
       "2  Union Minister for Road Transport and Highways...            None   \n",
       "3  Former Indian cricketer-turned-commentator Aak...            None   \n",
       "4  The death toll in the fire at a multi-storey b...            None   \n",
       "\n",
       "  title_translation content_translation summary translation  \\\n",
       "0              None                None                None   \n",
       "1              None                None                None   \n",
       "2              None                None                None   \n",
       "3              None                None                None   \n",
       "4              None                None                None   \n",
       "\n",
       "                author     country source_localtime bangladesh_localtime  \n",
       "0                 IANS  bangladesh       2024-03-02           2024-03-02  \n",
       "1  Morung Express News  bangladesh       2024-03-01           2024-03-01  \n",
       "2                 IANS  bangladesh       2024-03-01           2024-03-01  \n",
       "3                 IANS  bangladesh       2024-03-01           2024-03-01  \n",
       "4                 IANS  bangladesh       2024-03-01           2024-03-01  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains \n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "page = 1\n",
    "BASE_URL = 'https://www.morungexpress.com/'\n",
    "country = 'bangladesh'\n",
    "initial_url = f'{BASE_URL}search?keyword={country}&page={page}'\n",
    "\n",
    "all_news_links = []\n",
    "\n",
    "#COLLECTING ALL LINKS\n",
    "\n",
    "#USE WHILE LOOP TO FIND ALL PAGES. \n",
    "#AT THE TIME OF SCRAPING, THERE ARE 255 PAGES REGARDING BANGLADESH.\n",
    "\n",
    "#FIRST 3 PAGES TAKEN FOR SCRAPING.\n",
    "\n",
    "#while True\n",
    "for page in range(1,4):\n",
    "\n",
    "    initial_url = f'{BASE_URL}search?keyword={country}&page={page}'\n",
    "\n",
    "    response = requests.get(initial_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    all_news_lists = soup.find_all('li', class_ = 'view-list-item m-md-3 p-3')\n",
    "    \n",
    "    if len(all_news_lists) > 0:\n",
    "    \n",
    "        for each_news in all_news_lists:\n",
    "\n",
    "            all_news_links.append(each_news.find('div', class_ = 'post-title').find('a').get('href'))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        break\n",
    "        \n",
    "    #page+=1\n",
    "\n",
    "\n",
    "\n",
    "#SCRAPING NEWS DATA\n",
    "data_list = []\n",
    "counter = 0\n",
    "\n",
    "#SCRAPING PROCESS VERY LENGTHY FOR EACH LINK. SO, FIRST 16 LINKS TAKEN FOR THIS SCRIPT. \n",
    "\n",
    "for url in all_news_links[:16]:\n",
    "\n",
    "\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        #TITLE\n",
    "\n",
    "        title_tag = soup.find('h1', class_ = 'text-dark title-green-line-left')\n",
    "        title = title_tag.text.strip() if title_tag else 'Title not found'\n",
    "        \n",
    "\n",
    "        #DATE\n",
    "\n",
    "        #NO INFORMATION ABOUT TIME GIVEN IN THIS WEBSITE\n",
    "\n",
    "        date_info = soup.find('span', class_ = 'post-created')\n",
    "\n",
    "        if date_info:\n",
    "\n",
    "            date_data = date_info.find('span').text.strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "            try:\n",
    "                source_localtime = datetime.strptime(date_data.strip(), '%dth %B %Y')\n",
    "\n",
    "            except ValueError:\n",
    "\n",
    "                try:\n",
    "                    source_localtime = datetime.strptime(date_data.strip(), '%dst %B %Y')\n",
    "\n",
    "                except ValueError:\n",
    "            \n",
    "\n",
    "                    try:\n",
    "                        source_localtime = datetime.strptime(date_data.strip(), '%dnd %B %Y')\n",
    "\n",
    "                    except ValueError:\n",
    "\n",
    "                        try:\n",
    "                            source_localtime = datetime.strptime(date_data.strip(), '%drd %B %Y')\n",
    "                    \n",
    "                        except:\n",
    "                            source_localtime = 'None'\n",
    "                            date_data = 'Date data not found'\n",
    "                            \n",
    "            \n",
    "\n",
    "        #CONTENT\n",
    "\n",
    "        content = []\n",
    "\n",
    "        main_section = soup.find('section', {'id':'specialities'})\n",
    "\n",
    "        if main_section:\n",
    "\n",
    "            main_div = soup.find_all('div', class_ = 'post_content')\n",
    "\n",
    "            if main_div:\n",
    "\n",
    "                all_paras = main_div[1].find_all('p')\n",
    "\n",
    "                for each_para in all_paras:\n",
    "\n",
    "                    content.append(each_para.text)\n",
    "\n",
    "                full_content = ''.join(content)\n",
    "\n",
    "\n",
    "\n",
    "                full_content = re.sub('\\n|\\r', '', full_content)\n",
    "                full_content = full_content.replace('\\xa0','')\n",
    "\n",
    "                #AUTHOR\n",
    "                author_tag = all_paras[0].find('strong').text\n",
    "                \n",
    "                \n",
    "                author_split = author_tag.split('(')\n",
    "\n",
    "                if len(author_split) > 1:\n",
    "\n",
    "                    author = author_split[1]\n",
    "                    author_with_brackets = '('+author\n",
    "                    author = re.sub(r'[^\\w\\s]', '', author)\n",
    "\n",
    "                    author = author.strip()\n",
    "                    \n",
    "                    if len(author) > 20:\n",
    "                        \n",
    "                        author_strong_elements = all_paras[0].find_all('strong')          \n",
    "                            \n",
    "                        author = author_strong_elements[1].text\n",
    "                    \n",
    "\n",
    "                    temp_content = full_content.split(author_with_brackets.strip())\n",
    "\n",
    "                    if len(temp_content) > 1:\n",
    "                        full_content = temp_content[1]\n",
    "                    else:\n",
    "                        full_content = temp_content[0]\n",
    "\n",
    "\n",
    "                else:\n",
    "                    author = author_split[0] \n",
    "\n",
    "                    author = re.sub(r'[^\\w\\s]', '', author)\n",
    "\n",
    "                    author = author.strip()\n",
    "                    \n",
    "                    if len(author) > 20:\n",
    "                        \n",
    "                        author_strong_elements = all_paras[0].find_all('strong')\n",
    "                        \n",
    "                        author = author_strong_elements[1].text\n",
    "                    \n",
    "\n",
    "                    temp_content = full_content.split(author)\n",
    "\n",
    "                    if len(temp_content) > 1:\n",
    "                        full_content = temp_content[1]\n",
    "                    else:\n",
    "                        full_content = temp_content[0]\n",
    "\n",
    "\n",
    "\n",
    "                full_content = full_content.strip()\n",
    "\n",
    "            else:\n",
    "                full_content = 'Content not found'\n",
    "                author = 'Author not found'\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            full_content = 'Content not found'\n",
    "            author = 'Author not found'\n",
    "            \n",
    "        \n",
    "        #NO CONTENT SUMMARIES IN THIS WEBSITE\n",
    "        \n",
    "        content_summary = 'None'\n",
    "        summary_translation = 'None'\n",
    "        title_translation = 'None'\n",
    "        content_translation = 'None'\n",
    "#         source_localtime = 'None'\n",
    "        bangladesh_localtime = source_localtime\n",
    "\n",
    "        data_dict = {\n",
    "        \"url\": url,\n",
    "        \"title\": title,\n",
    "        \"content\": full_content,\n",
    "        \"content_summary\": content_summary,\n",
    "        \"title_translation\":title_translation,\n",
    "        \"content_translation\":content_translation,\n",
    "        \"summary translation\":summary_translation,\n",
    "        \"author\": author,\n",
    "        \"country\": country,\n",
    "        'source_localtime': source_localtime,\n",
    "        'bangladesh_localtime': bangladesh_localtime\n",
    "\n",
    "        }\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "        if (full_content != \"Content not Found\" and title != 'Title not found'):\n",
    "\n",
    "                if data_dict not in data_list:\n",
    "                    # Adding to data list\n",
    "                        data_list.append(data_dict)\n",
    "                        print(f'Link {counter} added')\n",
    "        else:\n",
    "                print(f'Link {counter}')\n",
    "                print('Skipped due to missing info.')\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "df.head()\n",
    "\n",
    "csv_filename = f\"{country}_The_Morung_Express.csv\"\n",
    "\n",
    "# Checking if the CSV file already exists\n",
    "if os.path.exists(csv_filename):\n",
    "    existing_df = pd.read_csv(csv_filename)\n",
    "    # Merging new and existing dataframe\n",
    "    df = pd.concat([existing_df, pd.DataFrame(data_list)], ignore_index=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"bangladesh_localtime\"])  # Converting the \"date\" column to datetime\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)  # Sorting the date\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)  \n",
    "else:\n",
    "    # If csv file does not exist, then we create a new CSV file with the scraped data\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88f782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
