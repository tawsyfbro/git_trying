{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48daff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link 1 added\n",
      "Link 2 added\n",
      "Link 6 added\n",
      "Link 7 added\n",
      "Link 8 added\n",
      "Link 9 added\n",
      "Link 11 added\n",
      "Link 12 added\n",
      "Link 13 added\n",
      "Link 14 added\n",
      "Link 15 added\n",
      "Link 16 added\n",
      "Link 17 added\n",
      "Link 18 added\n",
      "Link 19 added\n",
      "Link 20 added\n",
      "Link 21 added\n",
      "Link 22 added\n",
      "Link 23 added\n",
      "Link 25 added\n",
      "Link 26 added\n",
      "Link 27 added\n",
      "Link 28 added\n",
      "Link 29 added\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains \n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "page = 1\n",
    "BASE_URL = \"https://www.siasat.com/\"\n",
    "country = \"bangladesh\"\n",
    "initial_url = f'{BASE_URL}?s=&q={country}#gsc.tab=0&gsc.q={country}&gsc.page={page}'\n",
    "\n",
    "all_news_links = []\n",
    "\n",
    "\n",
    "#TAKING LINKS FROM FIRST 4 PAGES\n",
    "\n",
    "for page in range(1,4):\n",
    "\n",
    "    url = f'https://www.siasat.com/?s=&q=bangladesh#gsc.tab=0&gsc.q=bangladesh&gsc.page={page}'\n",
    "    # chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\")\n",
    "    # driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    MAX_RETRIES = 3\n",
    "    consecutive_failures = 0\n",
    "\n",
    "#THE WEBSITE DOESN'T LOAD PROPERLY IN THE FIRST TRY. BUT, LOADS IN ALL SECOND TRIES SO FAR.\n",
    "\n",
    "    while consecutive_failures < MAX_RETRIES:\n",
    "\n",
    "        try:\n",
    "\n",
    "            main_div = driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div/div/div/div/div/div/div[1]/div/div/div[1]/div[6]/div[2]/div[1]/div')\n",
    "\n",
    "            if main_div:\n",
    "\n",
    "#                     print(main_div)\n",
    "                    news = main_div.find_elements(By.CSS_SELECTOR, 'a')\n",
    "\n",
    "                    for n in news:\n",
    "\n",
    "                            news_text = n.get_attribute('data-ctorig')\n",
    "\n",
    "                            if news_text in all_news_links:\n",
    "                                continue\n",
    "                            else:\n",
    "                                all_news_links.append(news_text)\n",
    "\n",
    "            break \n",
    "\n",
    "\n",
    "        except NoSuchElementException:\n",
    "\n",
    "            consecutive_failures +=1\n",
    "            time.sleep(10)\n",
    "\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "#For some reason, a None object gets appended to the list. So, removing that here.\n",
    "modified_news_links = [i for i in all_news_links if i is not None]\n",
    "\n",
    "#SCRAPING THE LINKS\n",
    "\n",
    "data_list = []\n",
    "counter = 0\n",
    "\n",
    "for url in modified_news_links:\n",
    "        \n",
    "        if 'bangladesh' in url or 'bangladeshi' in url or 'bangladeshs' in url:\n",
    "        \n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            #TITLE\n",
    "\n",
    "            title_tag = soup.find('meta', {'property':'og:title'})\n",
    "            title = title_tag.get('content') if title_tag else 'Title not found'\n",
    "            title_translation = 'None'\n",
    "\n",
    "            #DATE\n",
    "\n",
    "            date_data= soup.find('meta',{'property':'article:modified_time'}).get('content')\n",
    "\n",
    "            if date_data:\n",
    "\n",
    "                only_date = date_data.split('T')[0]\n",
    "                only_time = date_data.split('T')[1]\n",
    "                time = f\"{only_time.split(':')[0]}:{only_time.split(':')[1]}\"\n",
    "                cleaned_date = f\"{only_date},{time}\"\n",
    "\n",
    "                source_localtime = datetime.strptime(cleaned_date, \"%Y-%m-%d,%H:%M\") + timedelta(hours = 5, minutes = 30) \n",
    "                bangladesh_localtime = source_localtime + timedelta(minutes=30)\n",
    "\n",
    "            else:\n",
    "\n",
    "                date_data = 'Date data not found'\n",
    "\n",
    "\n",
    "            #AUTHOR\n",
    "\n",
    "            author_tags = soup.find('span', class_ = 'author-meta single-author with-avatars')\n",
    "            author = author_tags.text.strip().split('Follow')[0].strip() if author_tags else 'Author not found'\n",
    "\n",
    "\n",
    "            #CONTENT SUMMARY\n",
    "\n",
    "            content_summary_tag = soup.find('h2', class_ = 'entry-sub-title')\n",
    "\n",
    "            content_summary = content_summary_tag.text if content_summary_tag else 'Content Summary not found'\n",
    "\n",
    "            summary_translation = 'None'\n",
    "\n",
    "            #CONTENT\n",
    "\n",
    "            content = []\n",
    "\n",
    "            main_content_id = soup.find('article',{'id':'the-post'})\n",
    "\n",
    "            if main_content_id:\n",
    "\n",
    "                all_paras = main_content_id.find_all('p')\n",
    "\n",
    "                for para in all_paras:\n",
    "                    content.append(para.text)\n",
    "\n",
    "                full_content = ''.join(content)\n",
    "                full_content = full_content.split('Get the news updates')[0]\n",
    "\n",
    "            else:\n",
    "                full_content = 'Content not found'\n",
    "\n",
    "            content_translation = 'None'\n",
    "\n",
    "\n",
    "            data_dict = {\n",
    "            \"url\": url,\n",
    "            \"title\": title,\n",
    "            \"content\": full_content,\n",
    "            \"content_summary\": content_summary,\n",
    "            \"title_translation\":title_translation,\n",
    "            \"content_translation\":content_translation,\n",
    "            \"summary translation\":summary_translation,\n",
    "            \"author\": author,\n",
    "            \"country\": country,\n",
    "            'source_localtime': source_localtime,\n",
    "            'bangladesh_localtime': bangladesh_localtime\n",
    "\n",
    "        }\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "        if (full_content != \"Content Not Found\" and title != 'Title not found'):\n",
    "\n",
    "                if data_dict not in data_list:\n",
    "                        # Adding to data list\n",
    "                        data_list.append(data_dict)\n",
    "                        print(f'Link {counter} added')\n",
    "        else:\n",
    "                print(f'Link {counter}')\n",
    "                print('Skipped due to missing info.')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "df.head()\n",
    "\n",
    "\n",
    "csv_filename = f\"{country}_Siasat_Daily.csv\"\n",
    "\n",
    "# Checking if the CSV file already exists\n",
    "if os.path.exists(csv_filename):\n",
    "    existing_df = pd.read_csv(csv_filename)\n",
    "    # Merging new and existing dataframe\n",
    "    df = pd.concat([existing_df, pd.DataFrame(data_list)], ignore_index=True)\n",
    "    df[\"bangladesh_localtime\"] = pd.to_datetime(df[\"bangladesh_localtime\"])  # Converting the \"date\" column to datetime\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.sort_values(by=\"date\", ascending=False)  # Sorting the date\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)  \n",
    "else:\n",
    "    # If csv file does not exist, then we create a new CSV file with the scraped data\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbba0462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content_summary</th>\n",
       "      <th>title_translation</th>\n",
       "      <th>content_translation</th>\n",
       "      <th>summary translation</th>\n",
       "      <th>author</th>\n",
       "      <th>country</th>\n",
       "      <th>source_localtime</th>\n",
       "      <th>bangladesh_localtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.siasat.com/bangladesh-embraces-ind...</td>\n",
       "      <td>Bangladesh embraces Indian medico's 'Save Girl...</td>\n",
       "      <td>Pune: Thousands of people and medicos in Bangl...</td>\n",
       "      <td>Dr. Rakh, who was invited for a 10-day long gu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Indo-Asian News Service</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-25 12:34:00</td>\n",
       "      <td>2024-02-25 13:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.siasat.com/bangladesh-pacer-mustaf...</td>\n",
       "      <td>Bangladesh pacer Mustafizur Rahman hospitalise...</td>\n",
       "      <td>Dhaka: Experienced left-arm pacer Mustafizur R...</td>\n",
       "      <td>Accident occurred while they were participatin...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Press Trust of India</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-18 15:27:00</td>\n",
       "      <td>2024-02-18 15:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.siasat.com/bangladeshi-nobel-laure...</td>\n",
       "      <td>Bangladeshi Nobel laureate Yunus charge-sheete...</td>\n",
       "      <td>Dhaka: Bangladesh’s anti-graft agency on Thurs...</td>\n",
       "      <td>Court has set March 3 for an indictment hearin...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Press Trust of India</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-01 21:07:00</td>\n",
       "      <td>2024-02-01 21:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.siasat.com/assam-would-have-been-p...</td>\n",
       "      <td>Assam would have been part of Bangladesh if in...</td>\n",
       "      <td>Guwahati: Union Home Minister Amit Shah on Sat...</td>\n",
       "      <td>\"Earlier, history was written and taught to us...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Press Trust of India</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-01-20 21:32:00</td>\n",
       "      <td>2024-01-20 22:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.siasat.com/will-protect-myanmar-bo...</td>\n",
       "      <td>Will protect India-Myanmar border with fencing...</td>\n",
       "      <td>Guwahati: Home Minister Amit Shah on Saturday ...</td>\n",
       "      <td>\"The India-Myanmar border will be protected li...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Press Trust of India</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-01-20 19:22:00</td>\n",
       "      <td>2024-01-20 19:52:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.siasat.com/bangladesh-embraces-ind...   \n",
       "1  https://www.siasat.com/bangladesh-pacer-mustaf...   \n",
       "2  https://www.siasat.com/bangladeshi-nobel-laure...   \n",
       "3  https://www.siasat.com/assam-would-have-been-p...   \n",
       "4  https://www.siasat.com/will-protect-myanmar-bo...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Bangladesh embraces Indian medico's 'Save Girl...   \n",
       "1  Bangladesh pacer Mustafizur Rahman hospitalise...   \n",
       "2  Bangladeshi Nobel laureate Yunus charge-sheete...   \n",
       "3  Assam would have been part of Bangladesh if in...   \n",
       "4  Will protect India-Myanmar border with fencing...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Pune: Thousands of people and medicos in Bangl...   \n",
       "1  Dhaka: Experienced left-arm pacer Mustafizur R...   \n",
       "2  Dhaka: Bangladesh’s anti-graft agency on Thurs...   \n",
       "3  Guwahati: Union Home Minister Amit Shah on Sat...   \n",
       "4  Guwahati: Home Minister Amit Shah on Saturday ...   \n",
       "\n",
       "                                     content_summary title_translation  \\\n",
       "0  Dr. Rakh, who was invited for a 10-day long gu...              None   \n",
       "1  Accident occurred while they were participatin...              None   \n",
       "2  Court has set March 3 for an indictment hearin...              None   \n",
       "3  \"Earlier, history was written and taught to us...              None   \n",
       "4  \"The India-Myanmar border will be protected li...              None   \n",
       "\n",
       "  content_translation summary translation                   author  \\\n",
       "0                None                None  Indo-Asian News Service   \n",
       "1                None                None     Press Trust of India   \n",
       "2                None                None     Press Trust of India   \n",
       "3                None                None     Press Trust of India   \n",
       "4                None                None     Press Trust of India   \n",
       "\n",
       "      country    source_localtime bangladesh_localtime  \n",
       "0  bangladesh 2024-02-25 12:34:00  2024-02-25 13:04:00  \n",
       "1  bangladesh 2024-02-18 15:27:00  2024-02-18 15:57:00  \n",
       "2  bangladesh 2024-02-01 21:07:00  2024-02-01 21:37:00  \n",
       "3  bangladesh 2024-01-20 21:32:00  2024-01-20 22:02:00  \n",
       "4  bangladesh 2024-01-20 19:22:00  2024-01-20 19:52:00  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
