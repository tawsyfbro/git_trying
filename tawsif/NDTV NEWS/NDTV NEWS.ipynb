{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdfd9a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed. Retrying...\n",
      "8\n",
      "Skipped due to missing info.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content_summary</th>\n",
       "      <th>title_translation</th>\n",
       "      <th>content_translation</th>\n",
       "      <th>summary translation</th>\n",
       "      <th>author</th>\n",
       "      <th>country</th>\n",
       "      <th>source_localtime</th>\n",
       "      <th>bangladesh_localtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.ndtv.com/india-news/wont-collect-b...</td>\n",
       "      <td>\"Won't Collect Biometric Data Of Myanmar, Ban...</td>\n",
       "      <td>Lalduhoma said his government won't collect bi...</td>\n",
       "      <td>The Chin people from Myanmar, the Bawm commun...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Press Trust of India</td>\n",
       "      <td>India</td>\n",
       "      <td>2024-02-29 14:36:00</td>\n",
       "      <td>2024-02-29 15:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ndtv.com/india-news/relationship-o...</td>\n",
       "      <td>Relationship Of Heart And Soul: President Mur...</td>\n",
       "      <td>President Murmu said that India and Bangladesh...</td>\n",
       "      <td>President Droupadi Murmu was addressing a you...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Press Trust of India</td>\n",
       "      <td>India</td>\n",
       "      <td>2024-02-28 04:03:00</td>\n",
       "      <td>2024-02-28 04:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ndtv.com/india-news/rules-to-fast-...</td>\n",
       "      <td>Amended Citizenship Rules Likely To Be Enforc...</td>\n",
       "      <td>The contentious Citizenship Amendment Act, whi...</td>\n",
       "      <td>Sources said the CAA will help refugees from ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Anindita Sanyal</td>\n",
       "      <td>India</td>\n",
       "      <td>2024-02-27 17:34:00</td>\n",
       "      <td>2024-02-27 18:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ndtv.com/india-news/following-indi...</td>\n",
       "      <td>\"Following Indian Supreme Court\": Top Banglad...</td>\n",
       "      <td>Appreciating the live streaming of court proce...</td>\n",
       "      <td>Chief Justice DY Chandrachud said both India ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ashish Kumar Bhargava</td>\n",
       "      <td>India</td>\n",
       "      <td>2024-02-26 22:33:00</td>\n",
       "      <td>2024-02-26 23:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://sports.ndtv.com/cricket/bpl-is-like-a-...</td>\n",
       "      <td>\"BPL Is Like A Circus\": Bangladesh Cricket Tea...</td>\n",
       "      <td>Bangladesh cricket team head coach Chandika Ha...</td>\n",
       "      <td>Chandika Hathurusingha said that the country d...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NDTV Sports Desk</td>\n",
       "      <td>India</td>\n",
       "      <td>2024-02-25 16:48:00</td>\n",
       "      <td>2024-02-25 17:18:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.ndtv.com/india-news/wont-collect-b...   \n",
       "1  https://www.ndtv.com/india-news/relationship-o...   \n",
       "2  https://www.ndtv.com/india-news/rules-to-fast-...   \n",
       "3  https://www.ndtv.com/india-news/following-indi...   \n",
       "4  https://sports.ndtv.com/cricket/bpl-is-like-a-...   \n",
       "\n",
       "                                               title  \\\n",
       "0   \"Won't Collect Biometric Data Of Myanmar, Ban...   \n",
       "1   Relationship Of Heart And Soul: President Mur...   \n",
       "2   Amended Citizenship Rules Likely To Be Enforc...   \n",
       "3   \"Following Indian Supreme Court\": Top Banglad...   \n",
       "4  \"BPL Is Like A Circus\": Bangladesh Cricket Tea...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Lalduhoma said his government won't collect bi...   \n",
       "1  President Murmu said that India and Bangladesh...   \n",
       "2  The contentious Citizenship Amendment Act, whi...   \n",
       "3  Appreciating the live streaming of court proce...   \n",
       "4  Bangladesh cricket team head coach Chandika Ha...   \n",
       "\n",
       "                                     content_summary title_translation  \\\n",
       "0   The Chin people from Myanmar, the Bawm commun...              None   \n",
       "1   President Droupadi Murmu was addressing a you...              None   \n",
       "2   Sources said the CAA will help refugees from ...              None   \n",
       "3   Chief Justice DY Chandrachud said both India ...              None   \n",
       "4  Chandika Hathurusingha said that the country d...              None   \n",
       "\n",
       "  content_translation summary translation                 author country  \\\n",
       "0                None                None   Press Trust of India   India   \n",
       "1                None                None   Press Trust of India   India   \n",
       "2                None                None        Anindita Sanyal   India   \n",
       "3                None                None  Ashish Kumar Bhargava   India   \n",
       "4                None                None       NDTV Sports Desk   India   \n",
       "\n",
       "     source_localtime bangladesh_localtime  \n",
       "0 2024-02-29 14:36:00  2024-02-29 15:06:00  \n",
       "1 2024-02-28 04:03:00  2024-02-28 04:33:00  \n",
       "2 2024-02-27 17:34:00  2024-02-27 18:04:00  \n",
       "3 2024-02-26 22:33:00  2024-02-26 23:03:00  \n",
       "4 2024-02-25 16:48:00  2024-02-25 17:18:00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "\n",
    "BASE_URL = \"https://www.ndtv.com/\"\n",
    "country = \"bangladesh\"\n",
    "initial_url = f\"{BASE_URL}/search?searchtext={country}\"\n",
    "# url = 'https://www.ndtv.com/search?searchtext=bangladesh'\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "# chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "# driver = webdriver.Chrome(options=chrome_options)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(initial_url)\n",
    "\n",
    "\n",
    "MAX_PAGES = 1\n",
    "clicks = 0\n",
    "MAX_RETRIES = 3\n",
    "consecutive_failures = 0\n",
    "ERROR_LIMIT = 5\n",
    "\n",
    "news_url_links = []\n",
    "while clicks < MAX_PAGES and consecutive_failures < MAX_RETRIES:\n",
    "    try:\n",
    "        # Waiting for the \"Load More Articles\" button to be clickable\n",
    "        show_more_button = WebDriverWait(driver, 15).until(\n",
    "            # EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(),'Load More Articles')]\"))\n",
    "            EC.element_to_be_clickable((By.XPATH, \"/html/body/div[2]/div/div/section/div[2]/div[2]/article/div/div/div/div[1]/div[1]/div[1]/div[3]/a\"))\n",
    "        )\n",
    "\n",
    "        # Scrolling a bit to ensure the button is fully in view (using JavaScript)\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", show_more_button)\n",
    "\n",
    "        # Using JavaScript to click the button\n",
    "        driver.execute_script(\"arguments[0].click();\", show_more_button)\n",
    "                \n",
    "        # Using sleep to ensure the content has loaded after clicking\n",
    "        time.sleep(5)\n",
    "        clicks += 1\n",
    "\n",
    "        # If successful, resetting the consecutive failures counter\n",
    "        consecutive_failures = 0\n",
    "        \n",
    "        if clicks == MAX_PAGES:\n",
    "            main_div_tag = driver.find_element(By.ID, 'tag_article')\n",
    "            news_details = main_div_tag.find_elements(By.CLASS_NAME, 'details')\n",
    "            \n",
    "            for news in news_details:\n",
    "            \n",
    "                news_h3 = news.find_element(By.CSS_SELECTOR, 'h3')\n",
    "                link_url = news_h3.find_element(By.CSS_SELECTOR,'a')\n",
    "                \n",
    "                news_url_links.append(link_url.get_attribute('href'))\n",
    "            \n",
    "\n",
    "    except (NoSuchElementException, ElementClickInterceptedException):\n",
    "        consecutive_failures += 1\n",
    "        print(f\"Attempt {consecutive_failures} failed. Retrying...\")\n",
    "        # Waiting before retrying\n",
    "        time.sleep(10)\n",
    "\n",
    "    except Exception as e:\n",
    "        consecutive_failures += 1\n",
    "        print(f\"Encountered an unexpected error: {str(e)}\")\n",
    "        if consecutive_failures >= ERROR_LIMIT:\n",
    "            print(\"Too many errors encountered. Stopping.\")\n",
    "            break\n",
    "            \n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "main_list = soup.find_all('ul', class_ = 'src_lst-ul')\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "#The main_list has a length of 3, that's because it's somehow scraping the same content of the first element for the third element as well. \n",
    "#So, we'll discard the last element of main_list. We pressed the 'Load More News' button only once, so we take the\n",
    "#first two elements. \n",
    "#If we use only soup.find, it'll only scrape the news up until 'Load More News' button, and nothing after that. \n",
    "\n",
    "news_lists = []\n",
    "for x in main_list[:-1]:\n",
    "    temp = x.find_all('li', class_ = 'src_lst-li')\n",
    "    \n",
    "    if temp:        \n",
    "        for all_news_lists in temp:\n",
    "            news_lists.append(all_news_lists)\n",
    "\n",
    "news_urls = []\n",
    "for news in news_lists:\n",
    "    news_div = news.find('div', class_='src_itm-ttl')\n",
    "    link = news_div.find('a')\n",
    "    news_urls.append(link.get('href'))\n",
    "\n",
    "counter = 0\n",
    "data_list = []\n",
    "\n",
    "for link in news_urls:\n",
    "    \n",
    "    country = 'India'   \n",
    "        \n",
    "    response = requests.get(link)\n",
    "   \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    title_tag = soup.find('h1', class_='sp-ttl')\n",
    "    title_mod = title_tag.text if title_tag else 'No Title Found'\n",
    "    title = re.sub('\\r\\n','',title_mod)   \n",
    "\n",
    "    date_element = soup.find('meta', {'itemprop':'datePublished'})\n",
    "    \n",
    "    if date_element:\n",
    "            date_data = date_element.get('content')\n",
    "            only_date = date_data.split('T')[0]\n",
    "            only_time = date_data.split('T')[1]\n",
    "            time = f\"{only_time.split(':')[0]}:{only_time.split(':')[1]}\"\n",
    "            cleaned_date = f\"{only_date},{time}\"\n",
    "\n",
    "            source_localtime = datetime.strptime(cleaned_date, \"%Y-%m-%d,%H:%M\")\n",
    "            bangladesh_localtime = source_localtime + timedelta(minutes=30)\n",
    "\n",
    "    else:\n",
    "        date_data = 'Date Data Not Found'\n",
    "        \n",
    "\n",
    "\n",
    "    content = []\n",
    "\n",
    "    content_div = soup.find('div', class_ = 'story__content')\n",
    "    alt_content_div = soup.find_all('div', class_ = 'sp-ttl-wrp')\n",
    "\n",
    "    if content_div:\n",
    "        paragraphs = content_div.find_all('p')\n",
    "        \n",
    "        author_tag = soup.find('span',{'itemprop':'name'})\n",
    "        author = author_tag.text if author_tag else 'Author not found'\n",
    "        \n",
    "    elif alt_content_div:\n",
    "        paragraphs = alt_content_div[1].find_all('p')\n",
    "        \n",
    "        author_tag = soup.find_all('span', {'itemprop':'name'})[-1]\n",
    "        author = author_tag.text if author_tag else 'Author not found'\n",
    "               \n",
    "    else:\n",
    "        full_content = 'Content Not Found'\n",
    "        \n",
    "\n",
    "    for p in paragraphs:\n",
    "        content.append(p.text)\n",
    "    \n",
    "    full_content = ' '.join(content)\n",
    "\n",
    "    full_content = re.sub('\\r\\n|\\xa0|\\n', ' ', full_content)\n",
    "    full_content = re.sub(\"\\'\", \"'\",full_content)\n",
    "    \n",
    "    #This is to remove the additional topic names mentioned, which is not part of the news. \n",
    "    temp_cuts = full_content.split('Topics mentioned in this article', 1)\n",
    "\n",
    "    full_content = temp_cuts[0].strip()\n",
    "\n",
    "    #This is to remove the scoorecard in news that cover live games.\n",
    "    temp_cuts = full_content.split('(Scorecard)', 1)\n",
    "\n",
    "    full_content = temp_cuts[0].strip()\n",
    "\n",
    "    \n",
    "    \n",
    "    content_summary_tag = soup.find('h2', class_ = 'sp-descp')\n",
    "    content_summary = content_summary_tag.text if content_summary_tag else 'Content summary not found'\n",
    "    \n",
    "\n",
    "    title_translation = 'None'\n",
    "    summary_translation = 'None'\n",
    "    content_translation = 'None'\n",
    "    \n",
    "    \n",
    "    data_dict = {\n",
    "            \"url\": link,\n",
    "            \"title\": title,\n",
    "            \"content\": full_content,\n",
    "            \"content_summary\": content_summary,\n",
    "            \"title_translation\":title_translation,\n",
    "            \"content_translation\":content_translation,\n",
    "            \"summary translation\":summary_translation,\n",
    "            \"author\": author,\n",
    "            \"country\": country,\n",
    "            'source_localtime': source_localtime,\n",
    "            'bangladesh_localtime': bangladesh_localtime\n",
    "\n",
    "        }\n",
    "\n",
    "    counter+=1\n",
    "\n",
    "\n",
    "    if (date_data != \"Date Data Not Found\" and full_content != \"Content Not Found\" and content_summary != \"Content summary not found\"):\n",
    "        if data_dict not in data_list:\n",
    "            # Adding to data list\n",
    "            data_list.append(data_dict)\n",
    "    else:\n",
    "        print(counter)\n",
    "        print('Skipped due to missing info.')\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "df.head()\n",
    "\n",
    "csv_filename = f\"{country}_NDTV_NEWS.csv\"\n",
    "\n",
    "# Checking if the CSV file already exists\n",
    "if os.path.exists(csv_filename):\n",
    "    existing_df = pd.read_csv(csv_filename)\n",
    "    # Merging new and existing dataframe\n",
    "    df = pd.concat([existing_df, pd.DataFrame(data_list)], ignore_index=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"bangladesh_localtime\"])  # Converting the \"date\" column to datetime\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)  # Sorting the date\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)  \n",
    "else:\n",
    "    # If csv file does not exist, then we create a new CSV file with the scraped data\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"bangladesh_localtime\"], format = \"%d-%m-%Y\")  # Converting the \"date\" column to datetime\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66216408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
