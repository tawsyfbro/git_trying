{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e399f527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content_summary</th>\n",
       "      <th>title_translation</th>\n",
       "      <th>content_translation</th>\n",
       "      <th>summary translation</th>\n",
       "      <th>author</th>\n",
       "      <th>country</th>\n",
       "      <th>source_localtime</th>\n",
       "      <th>bangladesh_localtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://thenewsglory.com/bangladesh-mall-fire-...</td>\n",
       "      <td>Bangladesh mall fire: 43 dead;  Many were seri...</td>\n",
       "      <td>Dhaka: 43 people were killed in a fire at a 6-...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The News Glory</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-03-01 10:39:00</td>\n",
       "      <td>2024-03-01 11:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://thenewsglory.com/bangladesh-election-n...</td>\n",
       "      <td>Bangladesh election not free and fair: US</td>\n",
       "      <td>The US demanded an investigation into the viol...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The News Glory</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-01-09 09:12:00</td>\n",
       "      <td>2024-01-09 09:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://thenewsglory.com/parliamentary-electio...</td>\n",
       "      <td>Parliamentary Elections in Bangladesh Tomorrow...</td>\n",
       "      <td>Dhaka: The 12th parliamentary election is goin...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The News Glory</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-01-06 18:40:00</td>\n",
       "      <td>2024-01-06 19:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://thenewsglory.com/bangladesh-court-sent...</td>\n",
       "      <td>Bangladesh court sentences Nobel laureate Muha...</td>\n",
       "      <td>A Bangladesh court on Monday sentenced Nobel P...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The News Glory</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-01-01 16:55:00</td>\n",
       "      <td>2024-01-01 17:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://thenewsglory.com/bangladesh-beat-new-z...</td>\n",
       "      <td>Bangladesh beat New Zealand for the first time...</td>\n",
       "      <td>Napier: New Zealand were bowled out for 98 run...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The News Glory</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2023-12-24 09:05:00</td>\n",
       "      <td>2023-12-24 09:35:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://thenewsglory.com/bangladesh-mall-fire-...   \n",
       "1  https://thenewsglory.com/bangladesh-election-n...   \n",
       "2  https://thenewsglory.com/parliamentary-electio...   \n",
       "3  https://thenewsglory.com/bangladesh-court-sent...   \n",
       "4  https://thenewsglory.com/bangladesh-beat-new-z...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Bangladesh mall fire: 43 dead;  Many were seri...   \n",
       "1          Bangladesh election not free and fair: US   \n",
       "2  Parliamentary Elections in Bangladesh Tomorrow...   \n",
       "3  Bangladesh court sentences Nobel laureate Muha...   \n",
       "4  Bangladesh beat New Zealand for the first time...   \n",
       "\n",
       "                                             content content_summary  \\\n",
       "0  Dhaka: 43 people were killed in a fire at a 6-...            None   \n",
       "1  The US demanded an investigation into the viol...            None   \n",
       "2  Dhaka: The 12th parliamentary election is goin...            None   \n",
       "3  A Bangladesh court on Monday sentenced Nobel P...            None   \n",
       "4  Napier: New Zealand were bowled out for 98 run...            None   \n",
       "\n",
       "  title_translation content_translation summary translation          author  \\\n",
       "0              None                None                None  The News Glory   \n",
       "1              None                None                None  The News Glory   \n",
       "2              None                None                None  The News Glory   \n",
       "3              None                None                None  The News Glory   \n",
       "4              None                None                None  The News Glory   \n",
       "\n",
       "      country    source_localtime bangladesh_localtime  \n",
       "0  bangladesh 2024-03-01 10:39:00  2024-03-01 11:09:00  \n",
       "1  bangladesh 2024-01-09 09:12:00  2024-01-09 09:42:00  \n",
       "2  bangladesh 2024-01-06 18:40:00  2024-01-06 19:10:00  \n",
       "3  bangladesh 2024-01-01 16:55:00  2024-01-01 17:25:00  \n",
       "4  bangladesh 2023-12-24 09:05:00  2023-12-24 09:35:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains \n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "\n",
    "page = 1\n",
    "BASE_URL = 'https://thenewsglory.com/'\n",
    "country = 'bangladesh'\n",
    "\n",
    "initial_url = f'{BASE_URL}page/{page}/?s={country}'\n",
    "\n",
    "#FINDING TOTAL PAGES\n",
    "\n",
    "response = requests.get(initial_url)\n",
    "    \n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "total_pages_element = soup.find('div', class_ ='jeg_navigation jeg_pagination jeg_pagenav_1 jeg_aligncenter no_navtext no_pageinfo')\n",
    "\n",
    "total_pages = total_pages_element.find('span').text.split('of ')[1]\n",
    "\n",
    "#COLLECTING ALL LINKS \n",
    "\n",
    "all_news_links = []\n",
    "\n",
    "for page in range(1,4):\n",
    "    \n",
    "    initial_url = f'{BASE_URL}page/{page}/?s={country}'\n",
    "    \n",
    "    response = requests.get(initial_url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    all_link_divs = soup.find_all('article', class_ = 'jeg_post jeg_pl_md_2 format-standard')\n",
    "    \n",
    "    for link_div in all_link_divs:\n",
    "\n",
    "        all_news_links.append(link_div.find('a').get('href'))\n",
    "\n",
    "\n",
    "#SCRAPING ALL THE LINKS \n",
    "\n",
    "counter = 0\n",
    "data_list = []\n",
    "\n",
    "for url in all_news_links:\n",
    "\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        #TITLE\n",
    "        title_tag = soup.find('h1', class_ = 'jeg_post_title')\n",
    "\n",
    "        title = title_tag.text if title_tag else 'Title not found'\n",
    "\n",
    "        title_translation = 'None'\n",
    "\n",
    "        #AUTHOR\n",
    "\n",
    "        author_div = soup.find('div', class_ = 'jeg_meta_author')\n",
    "        author = author_div.find('a').text if author_div else 'Author not found'\n",
    "\n",
    "        #DATE\n",
    "\n",
    "        date_info = soup.find('meta', {'property':'article:published_time'})\n",
    "\n",
    "        if date_info:\n",
    "\n",
    "            date_data = date_info.get('content')\n",
    "\n",
    "            only_date = date_data.split('T')[0]\n",
    "            only_time = date_data.split('T')[1]\n",
    "            time = f\"{only_time.split(':')[0]}:{only_time.split(':')[1]}\"\n",
    "            cleaned_date = f\"{only_date},{time}\"\n",
    "\n",
    "            source_localtime = datetime.strptime(cleaned_date, \"%Y-%m-%d,%H:%M\") \n",
    "            bangladesh_localtime = source_localtime + timedelta(minutes=30)\n",
    "\n",
    "        else:\n",
    "\n",
    "            date_data = 'Date data not found'\n",
    "\n",
    "        #NO CONTENT SUMMARIES IN THIS WEBSITE\n",
    "        content_summary = 'None'\n",
    "        summary_translation = 'None'\n",
    "\n",
    "        #CONTENT \n",
    "\n",
    "        content = []\n",
    "\n",
    "        content_div = soup.find('div', class_ = 'content-inner')\n",
    "\n",
    "        if content_div:\n",
    "\n",
    "            all_paras  = content_div.find_all('p')\n",
    "\n",
    "            for each_para in all_paras:\n",
    "\n",
    "                content.append(each_para.text)\n",
    "\n",
    "            full_content = ''.join(content)\n",
    "\n",
    "        else:\n",
    "\n",
    "            full_content = 'Content not found'\n",
    "\n",
    "        content_translation = 'None'\n",
    "        \n",
    "        data_dict = {\n",
    "                \"url\": url,\n",
    "                \"title\": title,\n",
    "                \"content\": full_content,\n",
    "                \"content_summary\": content_summary,\n",
    "                \"title_translation\":title_translation,\n",
    "                \"content_translation\":content_translation,\n",
    "                \"summary translation\":summary_translation,\n",
    "                \"author\": author,\n",
    "                \"country\": country,\n",
    "                'source_localtime': source_localtime,\n",
    "                'bangladesh_localtime': bangladesh_localtime\n",
    "\n",
    "            }\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "        if (full_content != \"Content not found\" or title != 'Title not found'):\n",
    "\n",
    "                    if data_dict not in data_list:\n",
    "                            # Adding to data list\n",
    "                            data_list.append(data_dict)\n",
    "#                             print(f'Link {counter} added')\n",
    "        else:\n",
    "                    print(f'Link {counter}')\n",
    "                    print('Skipped due to missing info.')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "df.head()\n",
    "\n",
    "csv_filename = f\"{country}_The_News_Glory.csv\"\n",
    "\n",
    "# Checking if the CSV file already exists\n",
    "if os.path.exists(csv_filename):\n",
    "    existing_df = pd.read_csv(csv_filename)\n",
    "    # Merging new and existing dataframe\n",
    "    df = pd.concat([existing_df, pd.DataFrame(data_list)], ignore_index=True)\n",
    "    df[\"bangladesh_localtime\"] = pd.to_datetime(df[\"bangladesh_localtime\"])  # Converting the \"date\" column to datetime\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.sort_values(by=\"date\", ascending=False)  # Sorting the date\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)  \n",
    "else:\n",
    "    # If csv file does not exist, then we create a new CSV file with the scraped data\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0721c55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
