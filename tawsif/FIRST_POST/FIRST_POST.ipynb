{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c651edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content_summary</th>\n",
       "      <th>title_translation</th>\n",
       "      <th>content_translation</th>\n",
       "      <th>summary translation</th>\n",
       "      <th>author</th>\n",
       "      <th>country</th>\n",
       "      <th>source_localtime</th>\n",
       "      <th>bangladesh_localtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.firstpost.com//explainers/explaine...</td>\n",
       "      <td>Explained: Why Bangladesh court halted adoptio...</td>\n",
       "      <td>Bangladesh has halted adoption of its wild ele...</td>\n",
       "      <td>The Bangladesh High Court on Sunday granted le...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>FP Explainers</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-26 18:27:00</td>\n",
       "      <td>2024-02-26 18:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.firstpost.com//india/after-demand-...</td>\n",
       "      <td>After demand from Assam's Barak Valley, Bangla...</td>\n",
       "      <td>A Bangladesh visa centre is set to come up in ...</td>\n",
       "      <td>A Bangladesh visa centre is set to come up in ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>FP Staff</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-19 14:10:00</td>\n",
       "      <td>2024-02-19 14:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.firstpost.com//world/bangladesh-re...</td>\n",
       "      <td>Bangladesh releases opposition leaders jailed ...</td>\n",
       "      <td>Two prominent opposition figures in Bangladesh...</td>\n",
       "      <td>The BNP and dozens of other parties boycotted ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>FP Staff</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-15 19:46:00</td>\n",
       "      <td>2024-02-15 20:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.firstpost.com//world/bangladesh-wo...</td>\n",
       "      <td>Bangladesh won't let in any more Rohingya, the...</td>\n",
       "      <td>Bangladesh declared on Wednesday that it will ...</td>\n",
       "      <td>Since the Rohingya are considered foreign intr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ajeyo Basu</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-07 22:00:00</td>\n",
       "      <td>2024-02-07 22:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.firstpost.com//world/myanmar-borde...</td>\n",
       "      <td>Myanmar border guards flee to Bangladesh as fi...</td>\n",
       "      <td>Officials in Bangladesh on Monday said that ov...</td>\n",
       "      <td>Officials in Bangladesh on Monday said that ov...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>FP Staff</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-05 18:16:00</td>\n",
       "      <td>2024-02-05 18:46:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.firstpost.com//explainers/explaine...   \n",
       "1  https://www.firstpost.com//india/after-demand-...   \n",
       "2  https://www.firstpost.com//world/bangladesh-re...   \n",
       "3  https://www.firstpost.com//world/bangladesh-wo...   \n",
       "4  https://www.firstpost.com//world/myanmar-borde...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Explained: Why Bangladesh court halted adoptio...   \n",
       "1  After demand from Assam's Barak Valley, Bangla...   \n",
       "2  Bangladesh releases opposition leaders jailed ...   \n",
       "3  Bangladesh won't let in any more Rohingya, the...   \n",
       "4  Myanmar border guards flee to Bangladesh as fi...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Bangladesh has halted adoption of its wild ele...   \n",
       "1  A Bangladesh visa centre is set to come up in ...   \n",
       "2  Two prominent opposition figures in Bangladesh...   \n",
       "3  Bangladesh declared on Wednesday that it will ...   \n",
       "4  Officials in Bangladesh on Monday said that ov...   \n",
       "\n",
       "                                     content_summary title_translation  \\\n",
       "0  The Bangladesh High Court on Sunday granted le...              None   \n",
       "1  A Bangladesh visa centre is set to come up in ...              None   \n",
       "2  The BNP and dozens of other parties boycotted ...              None   \n",
       "3  Since the Rohingya are considered foreign intr...              None   \n",
       "4  Officials in Bangladesh on Monday said that ov...              None   \n",
       "\n",
       "  content_translation summary translation         author     country  \\\n",
       "0                None                None  FP Explainers  bangladesh   \n",
       "1                None                None       FP Staff  bangladesh   \n",
       "2                None                None       FP Staff  bangladesh   \n",
       "3                None                None     Ajeyo Basu  bangladesh   \n",
       "4                None                None       FP Staff  bangladesh   \n",
       "\n",
       "     source_localtime bangladesh_localtime  \n",
       "0 2024-02-26 18:27:00  2024-02-26 18:57:00  \n",
       "1 2024-02-19 14:10:00  2024-02-19 14:40:00  \n",
       "2 2024-02-15 19:46:00  2024-02-15 20:16:00  \n",
       "3 2024-02-07 22:00:00  2024-02-07 22:30:00  \n",
       "4 2024-02-05 18:16:00  2024-02-05 18:46:00  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains \n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#COLLECTING THE LINKS\n",
    "\n",
    "BASE_URL = 'https://www.firstpost.com/'\n",
    "country= 'bangladesh'\n",
    "initial_url = f'{BASE_URL}tag/{country}/'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(initial_url)\n",
    "driver.maximize_window()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "show_more_button = driver.find_element(By.XPATH, '/html/body/div[1]/section/div[7]/div/div/div[4]/a')\n",
    "\n",
    "\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", show_more_button)\n",
    "time.sleep(5)\n",
    "\n",
    "number_of_clicks = 1\n",
    "\n",
    "while number_of_clicks > 0:\n",
    "\n",
    "    ActionChains(driver)\\\n",
    "    .click(show_more_button)\\\n",
    "    .perform()\n",
    "    \n",
    "    number_of_clicks -= 1\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", show_more_button)\n",
    "    time.sleep(5)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "all_link_divs = soup.find_all('li', class_ = 'jsx-94b310a290904418 str-lst')\n",
    "\n",
    "all_news_links = []\n",
    "\n",
    "for each_div in all_link_divs:\n",
    "    \n",
    "    all_news_links.append(each_div.find('a').get('href'))\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "    \n",
    "#SCRAPING ALL NEWS LINKS\n",
    "\n",
    "counter = 0\n",
    "data_list = []\n",
    "\n",
    "\n",
    "for link in all_news_links:\n",
    "    \n",
    "    url = f'{BASE_URL}{link}'\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    #TITLE\n",
    "    \n",
    "    title_tag = soup.find('h1', class_ = 'art-sec-ttl literatafont')\n",
    "    title = title_tag.text if title_tag else 'Title not found'\n",
    "    title_translation = 'None'\n",
    "    \n",
    "    #AUTHOR\n",
    "    \n",
    "    author_div = soup.find('div', class_ = 'art-dtls-info')\n",
    "    author = author_div.find('a').text\n",
    "    \n",
    "    \n",
    "    #DATE\n",
    "    \n",
    "    date_info = soup.find('meta', {'itemprop':'dateModified'})\n",
    "    \n",
    "    if date_info:\n",
    "        \n",
    "        date_data = date_info.get('content')\n",
    "        \n",
    "        only_date = date_data.split('T')[0]\n",
    "        only_time = date_data.split('T')[1]\n",
    "        time = f\"{only_time.split(':')[0]}:{only_time.split(':')[1]}\"\n",
    "        cleaned_date = f\"{only_date},{time}\"\n",
    "\n",
    "        source_localtime = datetime.strptime(cleaned_date, \"%Y-%m-%d,%H:%M\")\n",
    "        bangladesh_localtime = source_localtime + timedelta(minutes=30)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        date_data = 'Date data not found'\n",
    "        \n",
    "    #CONTENT SUMMARY\n",
    "    \n",
    "    content_summary_tag = soup.find('span', class_ = 'less-cont')\n",
    "    content_summary = content_summary_tag.text if content_summary_tag else 'Content Summary not found'\n",
    "    \n",
    "    summary_translation = 'None'\n",
    "    \n",
    "    #CONTENT\n",
    "    \n",
    "    content = []\n",
    "\n",
    "    main_content = soup.find('div', class_ = 'main-dtls-wrap max-dtls-width')\n",
    "\n",
    "    if main_content:\n",
    "    \n",
    "        all_paras = main_content.find_all('p')\n",
    "\n",
    "        all_paras.pop()\n",
    "\n",
    "        all_paras.pop(0)\n",
    "\n",
    "        for each_para in all_paras:\n",
    "\n",
    "            content.append(each_para.text)\n",
    "\n",
    "        full_content = ''.join(content)\n",
    "\n",
    "\n",
    "        full_content = re.sub(\"\\x80|\\x9d|\\x99|\\x9c\\x9a\",'',full_content)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        full_content = 'Content not found'\n",
    "        \n",
    "    content_translation = 'None'\n",
    "    \n",
    "    data_dict = {\n",
    "            \"url\": url,\n",
    "            \"title\": title,\n",
    "            \"content\": full_content,\n",
    "            \"content_summary\": content_summary,\n",
    "            \"title_translation\":title_translation,\n",
    "            \"content_translation\":content_translation,\n",
    "            \"summary translation\":summary_translation,\n",
    "            \"author\": author,\n",
    "            \"country\": country,\n",
    "            'source_localtime': source_localtime,\n",
    "            'bangladesh_localtime': bangladesh_localtime\n",
    "\n",
    "        }\n",
    "\n",
    "    counter+=1\n",
    "\n",
    "\n",
    "    if (date_data != \"Date Data Not Found\" and full_content != \"Content Not Found\" and content_summary != \"Content summary not found\"):\n",
    "        if data_dict not in data_list:\n",
    "            # Adding to data list\n",
    "            data_list.append(data_dict)\n",
    "    else:\n",
    "        print(counter)\n",
    "        print('Skipped due to missing info.')\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "df.head()\n",
    "\n",
    "    \n",
    "    \n",
    "csv_filename = f\"{country}_First_Post.csv\"\n",
    "\n",
    "# Checking if the CSV file already exists\n",
    "if os.path.exists(csv_filename):\n",
    "    existing_df = pd.read_csv(csv_filename)\n",
    "    # Merging new and existing dataframe\n",
    "    df = pd.concat([existing_df, pd.DataFrame(data_list)], ignore_index=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"bangladesh_localtime\"])  # Converting the \"date\" column to datetime\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)  # Sorting the date\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)  \n",
    "else:\n",
    "    # If csv file does not exist, then we create a new CSV file with the scraped data\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"bangladesh_localtime\"], format = \"%d-%m-%Y\")  # Converting the \"date\" column to datetime\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
