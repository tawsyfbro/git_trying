{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aebc4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link 1 added\n",
      "Link 2 added\n",
      "Link 3 added\n",
      "Link 4 added\n",
      "Link 5 added\n",
      "Link 6 added\n",
      "Link 7 added\n",
      "Link 8 added\n",
      "Link 9 added\n",
      "Link 10 added\n",
      "Link 11 added\n",
      "Link 12 added\n",
      "Link 13 added\n",
      "Link 14\n",
      "Skipped due to missing info.\n",
      "Link 15\n",
      "Skipped due to missing info.\n",
      "Link 16 added\n",
      "Link 17\n",
      "Skipped due to missing info.\n",
      "Link 18 added\n",
      "Link 19 added\n",
      "Link 20 added\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content_summary</th>\n",
       "      <th>title_translation</th>\n",
       "      <th>content_translation</th>\n",
       "      <th>summary translation</th>\n",
       "      <th>author</th>\n",
       "      <th>country</th>\n",
       "      <th>source_localtime</th>\n",
       "      <th>bangladesh_localtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.dailyexcelsior.com/govt-allows-oni...</td>\n",
       "      <td>Govt allows onion exports to Bangladesh, Mauri...</td>\n",
       "      <td>The government on Thursday permitted traders t...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Daily Excelsior</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-22 17:04:00</td>\n",
       "      <td>2024-02-22 17:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.dailyexcelsior.com/bangladesh-repa...</td>\n",
       "      <td>Bangladesh repatriates 330 Myanmar soldiers</td>\n",
       "      <td>Bangladesh on Thursday repatriated 330 of Myan...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Daily Excelsior</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-15 17:34:00</td>\n",
       "      <td>2024-02-15 18:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.dailyexcelsior.com/suspend-trans-s...</td>\n",
       "      <td>Suspend trans-shipment of Bangladesh export ca...</td>\n",
       "      <td>Apparel exporters body AEPC on Thursday urged ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Daily Excelsior</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-15 11:39:00</td>\n",
       "      <td>2024-02-15 12:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.dailyexcelsior.com/india-is-bangla...</td>\n",
       "      <td>India is Bangladesh’s largest export destinati...</td>\n",
       "      <td>India is today Bangladesh’s largest export des...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Daily Excelsior</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-13 15:42:00</td>\n",
       "      <td>2024-02-13 16:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.dailyexcelsior.com/india-banglades...</td>\n",
       "      <td>India-Bangladesh ties role model for neighbour...</td>\n",
       "      <td>India’s decision to fence its border with Myan...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Daily Excelsior</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>2024-02-08 18:55:00</td>\n",
       "      <td>2024-02-08 19:25:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.dailyexcelsior.com/govt-allows-oni...   \n",
       "1  https://www.dailyexcelsior.com/bangladesh-repa...   \n",
       "2  https://www.dailyexcelsior.com/suspend-trans-s...   \n",
       "3  https://www.dailyexcelsior.com/india-is-bangla...   \n",
       "4  https://www.dailyexcelsior.com/india-banglades...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Govt allows onion exports to Bangladesh, Mauri...   \n",
       "1        Bangladesh repatriates 330 Myanmar soldiers   \n",
       "2  Suspend trans-shipment of Bangladesh export ca...   \n",
       "3  India is Bangladesh’s largest export destinati...   \n",
       "4  India-Bangladesh ties role model for neighbour...   \n",
       "\n",
       "                                             content content_summary  \\\n",
       "0  The government on Thursday permitted traders t...            None   \n",
       "1  Bangladesh on Thursday repatriated 330 of Myan...            None   \n",
       "2  Apparel exporters body AEPC on Thursday urged ...            None   \n",
       "3  India is today Bangladesh’s largest export des...            None   \n",
       "4  India’s decision to fence its border with Myan...            None   \n",
       "\n",
       "  title_translation content_translation summary translation           author  \\\n",
       "0              None                None                None  Daily Excelsior   \n",
       "1              None                None                None  Daily Excelsior   \n",
       "2              None                None                None  Daily Excelsior   \n",
       "3              None                None                None  Daily Excelsior   \n",
       "4              None                None                None  Daily Excelsior   \n",
       "\n",
       "      country    source_localtime bangladesh_localtime  \n",
       "0  bangladesh 2024-02-22 17:04:00  2024-02-22 17:34:00  \n",
       "1  bangladesh 2024-02-15 17:34:00  2024-02-15 18:04:00  \n",
       "2  bangladesh 2024-02-15 11:39:00  2024-02-15 12:09:00  \n",
       "3  bangladesh 2024-02-13 15:42:00  2024-02-13 16:12:00  \n",
       "4  bangladesh 2024-02-08 18:55:00  2024-02-08 19:25:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "\n",
    "BASE_URL = \"https://www.dailyexcelsior.com/\"\n",
    "country = \"bangladesh\"\n",
    "initial_url = f\"{BASE_URL}/about/{country}\"\n",
    "\n",
    "#FINDING TOTAL PAGES AVAILABLE\n",
    "\n",
    "#WEBSITE HAS AROUND 882 PAGES. EACH PAGES TAKES QUITE A WHILE TO LOAD AND GIVE OUTPUT. SO THE ENTIRE PROCESS WILL TAKE \n",
    "#A LONG TIME.\n",
    "#FOR DEMO, I'VE DONE TILL THE 10th PAGE.\n",
    "\n",
    "page = 1\n",
    "while True:\n",
    "    \n",
    "    url = f'{BASE_URL}page/{page}/?s={country}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    buttons_div = soup.find('div', class_ = 'page-nav td-pb-padding-side' )\n",
    "    button_present = buttons_div.find('a', {'aria-label': 'next-page'})\n",
    "    \n",
    "    if button_present:\n",
    "                \n",
    "        page+=1\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        break\n",
    "    \n",
    "    if page>10:\n",
    "        \n",
    "        break\n",
    "\n",
    "\n",
    "#SCRAPING ALL THE NEWS LINKS\n",
    "\n",
    "\n",
    "news_url_links = []\n",
    "\n",
    "for page in range(1,3):\n",
    "\n",
    "#     url = f'https://www.dailyexcelsior.com/page/{page}/?s=bangladesh'\n",
    "    url = f'{BASE_URL}page/{page}/?s={country}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    main_div = soup.find('div', class_ = 'td-main-content-wrap td-container-wrap')\n",
    "\n",
    "    if main_div:\n",
    "\n",
    "        link_div = main_div.find_all('div', class_ = 'td_module_16 td_module_wrap td-animation-stack')\n",
    "\n",
    "        for div in link_div:\n",
    "\n",
    "            link_h3 = div.find('h3', class_ = 'entry-title td-module-title')\n",
    "\n",
    "            link_tag = link_h3.find('a')\n",
    "\n",
    "            news_url_links.append(link_tag.get('href'))\n",
    "\n",
    "            \n",
    "#SCRAPING ALL NEWS FROM LINKS\n",
    "\n",
    "counter = 0\n",
    "data_list = []\n",
    "\n",
    "for link in news_url_links:\n",
    "\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "        #TITLE\n",
    "\n",
    "        title_tag = soup.find('h1', class_ = 'entry-title')\n",
    "        title = title_tag.text if title_tag else 'Title not found'\n",
    "        title\n",
    "\n",
    "        #AUTHOR\n",
    "\n",
    "        author_div = soup.find('div', class_ = 'td-module-meta-info')\n",
    "        author_tag = author_div.find('div', class_ = 'td-post-author-name')\n",
    "        author = (author_tag.find('a').text) if author_div else 'Author not found'\n",
    "\n",
    "\n",
    "        #DATE \n",
    "\n",
    "        date_div = soup.find('meta', {'property': 'article:modified_time'})\n",
    "\n",
    "\n",
    "        if date_div:\n",
    "\n",
    "            date_data = date_div.get('content')\n",
    "\n",
    "            only_date = date_data.split('T')[0]\n",
    "            only_time = date_data.split('T')[1]\n",
    "            time = f\"{only_time.split(':')[0]}:{only_time.split(':')[1]}\"\n",
    "            cleaned_date = f\"{only_date},{time}\"\n",
    "\n",
    "            source_localtime = datetime.strptime(cleaned_date, \"%Y-%m-%d,%H:%M\")\n",
    "            bangladesh_localtime = source_localtime + timedelta(minutes=30)\n",
    "\n",
    "\n",
    "        else:\n",
    "            date_data = 'Date Data Not Found'\n",
    "\n",
    "        #CONTENT\n",
    "\n",
    "        content = []\n",
    "\n",
    "        content_tag = soup.find('div', class_ = 'td-post-content tagdiv-type')\n",
    "\n",
    "        if content_tag:\n",
    "\n",
    "            all_paras = content_tag.find_all('p')\n",
    "\n",
    "            for para in all_paras:\n",
    "\n",
    "                content.append(para.text)\n",
    "\n",
    "            full_content = ' '.join(content)\n",
    "            full_content = re.sub('\\n|\\r|\\xa0','',full_content)\n",
    "            full_content = full_content.replace('(PTI)','')\n",
    "            \n",
    "            full_content = full_content.split(':',1)\n",
    "            \n",
    "            if len(full_content) > 1:\n",
    "                \n",
    "                full_content = full_content[1]\n",
    "            else:\n",
    "                full_content = full_content[0]\n",
    "            \n",
    "            full_content = full_content.strip()\n",
    "\n",
    "        else:\n",
    "\n",
    "            full_content = 'Content Not Found'\n",
    "\n",
    "\n",
    "        #No CONTENT SUMMARY Available for this News Website\n",
    "        \n",
    "        content_summary = 'None'\n",
    "        \n",
    "        title_translation = 'None'\n",
    "        summary_translation = 'None'\n",
    "        content_translation = 'None'\n",
    "\n",
    "        \n",
    "        data_dict = {\n",
    "            \"url\": link,\n",
    "            \"title\": title,\n",
    "            \"content\": full_content,\n",
    "            \"content_summary\": content_summary,\n",
    "            \"title_translation\":title_translation,\n",
    "            \"content_translation\":content_translation,\n",
    "            \"summary translation\":summary_translation,\n",
    "            \"author\": author,\n",
    "            \"country\": country,\n",
    "            'source_localtime': source_localtime,\n",
    "            'bangladesh_localtime': bangladesh_localtime\n",
    "\n",
    "        }\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "        if (date_data != \"Date Data Not Found\" and full_content != \"Content Not Found\"):\n",
    "            if data_dict not in data_list:\n",
    "                # Adding to data list\n",
    "                data_list.append(data_dict)\n",
    "                print(f'Link {counter} added')\n",
    "        else:\n",
    "            print(f'Link {counter}')\n",
    "            print('Skipped due to missing info.')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "df.head()\n",
    "\n",
    "\n",
    "csv_filename = f\"{country}_Daily_Excelsior.csv\"\n",
    "\n",
    "# Checking if the CSV file already exists\n",
    "if os.path.exists(csv_filename):\n",
    "    existing_df = pd.read_csv(csv_filename)\n",
    "    # Merging new and existing dataframe\n",
    "    df = pd.concat([existing_df, pd.DataFrame(data_list)], ignore_index=True)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"bangladesh_localtime\"])  # Converting the \"date\" column to datetime\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)  # Sorting the date\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)  \n",
    "else:\n",
    "    # If csv file does not exist, then we create a new CSV file with the scraped data\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"bangladesh_localtime\"], format = \"%d-%m-%Y\")  # Converting the \"date\" column to datetime\n",
    "    df = df.sort_values(by=\"bangladesh_localtime\", ascending=False)\n",
    "    df = df.drop_duplicates(subset=[\"title\"], keep=\"first\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(csv_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
